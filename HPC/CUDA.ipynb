{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yzn1nIlvfxWM",
    "outputId": "d236e652-af6f-4630-cc40-45cc574421b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/afnan47/cuda.git\n",
      "  Cloning https://github.com/afnan47/cuda.git to /tmp/pip-req-build-9_h0mraw\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/afnan47/cuda.git /tmp/pip-req-build-9_h0mraw\n",
      "  Resolved https://github.com/afnan47/cuda.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: NVCCPlugin\n",
      "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4289 sha256=9fa6267da8cc6d6bb942a256a0c5f8707fd3b0c33abb3cbd72980c429d2683d8\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-q4si76cz/wheels/aa/f3/44/e10c1d226ec561d971fcd4b0463f6bff08602afa928a3e7bc7\n",
      "Successfully built NVCCPlugin\n",
      "Installing collected packages: NVCCPlugin\n",
      "Successfully installed NVCCPlugin-0.0.2\n",
      "created output directory at /content/src\n",
      "Out bin /content/result.out\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/afnan47/cuda.git\n",
    "%load_ext nvcc_plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JFe1ouzBf5iU",
    "outputId": "14f310d3-02e0-437b-82d0-6f14ebb698e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hpc41.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile hpc41.cu\n",
    "\n",
    "#include<iostream>\n",
    "#include<cuda_runtime.h>\n",
    "\n",
    "__global__ void addvect(int *A,int *B,int *C,int n)\n",
    "{\n",
    "    int i= blockIdx.x *  blockDim.x + threadIdx.x;\n",
    "\n",
    "    if(i<n)\n",
    "    {\n",
    "        C[i]=A[i]+B[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    int n=100;\n",
    "    int *A,*B,*C;\n",
    "    int size=n*sizeof(int);\n",
    "\n",
    "    cudaMallocHost(&A,size);\n",
    "    cudaMallocHost(&B,size);\n",
    "    cudaMallocHost(&C,size);\n",
    "\n",
    "    for(int i=0;i<n;i++)\n",
    "    {\n",
    "        A[i]=i;\n",
    "        B[i]=i*2;\n",
    "    }\n",
    "\n",
    "    int *da,*db,*dc;\n",
    "\n",
    "    cudaMalloc(&da,size);\n",
    "    cudaMalloc(&db,size);\n",
    "    cudaMalloc(&dc,size);\n",
    "\n",
    "    cudaMemcpy(da,A,size,cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(db,B,size,cudaMemcpyHostToDevice);\n",
    "\n",
    "    int blocksize=256;\n",
    "    int numblock=(n+blocksize-1)/blocksize;\n",
    "\n",
    "    addvect<<<numblock,blocksize>>>(da,db,dc,n);\n",
    "\n",
    "    cudaMemcpy(C,dc,size,cudaMemcpyDeviceToHost);\n",
    "\n",
    "    for(int i=0;i<10;i++)\n",
    "    {\n",
    "        printf(\"%d + %d = %d \\n\",A[i],B[i],C[i]);\n",
    "    }\n",
    "\n",
    "    cudaFree(da);\n",
    "    cudaFree(db);\n",
    "    cudaFree(dc);\n",
    "\n",
    "    cudaFreeHost(A);\n",
    "    cudaFreeHost(B);\n",
    "    cudaFreeHost(C);\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0eSKSmFqgMAj",
    "outputId": "f092c18c-9ffe-4409-adc6-31b0656ce0df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 + 0 = 0 \n",
      "1 + 2 = 3 \n",
      "2 + 4 = 6 \n",
      "3 + 6 = 9 \n",
      "4 + 8 = 12 \n",
      "5 + 10 = 15 \n",
      "6 + 12 = 18 \n",
      "7 + 14 = 21 \n",
      "8 + 16 = 24 \n",
      "9 + 18 = 27 \n"
     ]
    }
   ],
   "source": [
    "!nvcc -o hpc41 hpc41.cu -Xcompiler -fopenmp\n",
    "!./hpc41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JDBLqXH9gS2a",
    "outputId": "70a5cd6c-6f24-4eb3-e32e-6e2915d05344"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hpc42.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile hpc42.cu\n",
    "#include <iostream>\n",
    "#include<time.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// CUDA kernel for matrix multiplication\n",
    "__global__ void matrixMul(float *a, float *b, float *c, int n) {\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (row < n && col < n) {\n",
    "        float sum = 0.0f;\n",
    "        for (int k = 0; k < n; ++k) {\n",
    "            sum += a[row * n + k] * b[k * n + col];\n",
    "        }\n",
    "        c[row * n + col] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int n = 16; // Size of matrices\n",
    "    int size = n * n * sizeof(float);\n",
    "\n",
    "    // Allocate memory on host\n",
    "    float *h_a, *h_b, *h_c;\n",
    "    h_a = (float*)malloc(size);\n",
    "    h_b = (float*)malloc(size);\n",
    "    h_c = (float*)malloc(size);\n",
    "\n",
    "    // Initialize matrices\n",
    "    for (int i = 0; i < n * n; ++i) {\n",
    "        h_a[i] = 1.0f;\n",
    "        h_b[i] = 2.0f;\n",
    "    }\n",
    "\n",
    "    // Allocate memory on device\n",
    "    float *d_a, *d_b, *d_c;\n",
    "    cudaMalloc((void**)&d_a, size);\n",
    "    cudaMalloc((void**)&d_b, size);\n",
    "    cudaMalloc((void**)&d_c, size);\n",
    "\n",
    "    // Copy data from host to device\n",
    "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    // Set grid and block dimensions for matrix multiplication\n",
    "    dim3 blockDim(16, 16);\n",
    "    dim3 gridDim((n + blockDim.x - 1) / blockDim.x, (n + blockDim.y - 1) / blockDim.y);\n",
    "\n",
    "    // Perform matrix multiplication on device\n",
    "    matrixMul<<<gridDim, blockDim>>>(d_a, d_b, d_c, n);\n",
    "\n",
    "    // Copy result back to host\n",
    "    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // Output result of matrix multiplication\n",
    "    std::cout << \"Matrix multiplication result:\" << std::endl;\n",
    "    for (int i = 0; i < n; ++i) {\n",
    "        for (int j = 0; j < n; ++j) {\n",
    "            std::cout << h_c[i * n + j] << \" \";\n",
    "        }\n",
    "        std::cout << std::endl;\n",
    "    }\n",
    "\n",
    "    // Free device memory\n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_c);\n",
    "\n",
    "    // Free host memory\n",
    "    free(h_a);\n",
    "    free(h_b);\n",
    "    free(h_c);\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zE_SXFUyeETY",
    "outputId": "c490066b-e3e0-4fbe-e566-f895d1c78d6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix multiplication result:\n",
      "32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 \n",
      "32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 \n",
      "32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 \n",
      "32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 \n",
      "32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 \n",
      "32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 \n",
      "32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 \n",
      "32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 \n",
      "32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 \n",
      "32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 \n",
      "32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 \n",
      "32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 \n",
      "32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 \n",
      "32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 \n",
      "32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 \n",
      "32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 \n"
     ]
    }
   ],
   "source": [
    "!nvcc -o hpc42 hpc42.cu -Xcompiler -fopenmp\n",
    "!./hpc42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MPhfRrsdeTPI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
